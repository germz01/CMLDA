\chapter{The network} % (fold)
\label{cha:the_network}
	In this first chapter, we provide some informations about the Artificial Neural Network, i.e. a fully
	connected Multilayer Perceptron, we implemented from scratch. We'll describe both the network's structure and
	the algorithm we used in order to make our network \textit{learn} from the data used during the testing and
	validation phases. Finally we'll present the loss function we have chosen for our network, and we'll provide
	and explanation on how it is differentiable. We'll use the notation proposed in \cite{Goodfellow-et-al-2016}.

	\section{The network's structure} % (fold)
	\label{sec:the_network_s_structure}
		Since we have to write from scratch an \textit{Artificial Neural Network}, ANN for short, we have
		considered some alternatives before choosing the network's final structure. We agreed on a structure
		composed by one \textit{input layer}, two \textit{hidden layers} and one \textit{output layer}. As
		convention, the number of units in the input layer is egual to the number
		of features of the dataset that is used for the learning, validation and testing phases. The two
		hidden layers contain, respectively, four and eight \textit{hidden neurons}, following the convention of
		putting an increasing series of powers of two as number of hidden units per layer. The number of neurons
		for the output layer depends on the kind of task the network is trying to fullfil. In the case of a
		\textit{classification task}, like the MONKS dataset \cite{Dua:2019}, we have decided to put one unit in
		the output layer, while in the case of a \textit{regression task}, like the CUP dataset, we have decided to
		put two units in the output layer. As we have seen studying the papers and books for gathering the
		necessary knowledge for the project, as \cite{Goodfellow-et-al-2016,haykin2009neural,mitchell1997machine},
		choosing to consider the network's structure as an \textit{hyperparameter}, that is, a variable, could
		lead to a series of difficult choices during the validation phase, so we have decided to fix the ANN
		structure to the one described for both the task we have to fullfil, changing only the number of units in
		the output layer from task to task.
	% section the_network_s_structure (end)

	\section{The network's initialization} % (fold)
	\label{sec:the_network_s_initialization}

	% section the_network_s_initialization (end)

	\section{The back-propagation algorithm} % (fold)
	\label{sec:the_back-propagation_algorithm}
		The learning procedure for our ANN essentialy consist in two distinct phases:

		\begin{enumerate}
			\item compute the network's \textit{gradient}, that is, the derivative of the cost function
			$\nabla_{\theta} J(\theta)$ with respect to every network's unit;
			\item optimize the information gathered during the first phase using a distinct technique, like the
			ones described in chapter \ref{cha:optimizers};
		\end{enumerate}

		For computing the gradient we have chosen to use
		the well known \textit{backpropagation algorithm}, firstly introduced in \cite{10028086174} and described
		in \cite{Goodfellow-et-al-2016,haykin2009neural,mitchell1997machine}. This algorithm is
		also composed by two phases, a first phase, that is, the \textit{forward propagation}, in which the
		feature vector $\mathbf{x}$ given in input has to flow from the input layer through the hidden layers and,
		finally, the output layer, giving the approximation $\hat{\mathbf{y}}$ as output, and a second one, that
		is, the \textit{back-propagation}, which allows the informtion to flow backward through the network in
		order to compute the gradient by applying the Chain Rule of Calculus, that is, a formula for computing the
		derivative of a composition of functions. It is import to note that with the term back-propagation we mean
		only the method for computing the gradient, not the whole learning algorithm. We now provide the
		pseudocode for the forward propagation and the back-propagation phases.

		\begin{algorithm}
			\caption{Forward propagation through a typical (deep) neural network and the computation of the cost
			function.}
			\label{alg:forward_propagation}
			\begin{algorithmic}[1]
				\Procedure{Forward propagation}{$l$, $\mathbf{W}^{(i)} \ i \in \{ 1, \ldots, l \}$,
				$\mathbf{b}^{(i)} \ i \in \{ 1, \ldots, l \}$, $\mathbf{x}$, $\mathbf{y}$}
					\State $\mathbf{h}^{(0)} = \mathbf{x}$
					\For{$k = 1, \ldots, l$}
						\State $\mathbf{a}^{(k)} = \mathbf{b}^{(k)} + \mathbf{W}^{(k)}\mathbf{h}^{k - 1}$
						\State $\mathbf{h}^{(k)} = f(\mathbf{a}^{(k)})$
					\EndFor
					\State $\hat{\mathbf{y}} = \mathbf{h}^{(l)}$
					\State $J = L(\hat{\mathbf{y}}, \mathbf{y}) + \lambda \Omega(\theta)$
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}

		\begin{algorithm}
			\caption{Backward computation for the (deep) neural network of algorithm \ref{alg:forward_propagation}.
			}
			\label{alg:backward_propagation}
			\begin{algorithmic}[1]
				\Procedure{Backward propagation}{}
					\State $\mathbf{g} \leftarrow \nabla_{\hat{\mathbf{y}}}J = \nabla_{\hat{\mathbf{y}}}
					L(\hat{\mathbf{y}}, \mathbf{y})$
					\For{$k = l, l - 1, \ldots, 1$}
						\State $\mathbf{g} \leftarrow \nabla_{\mathbf{a}^{(k)}}J = \mathbf{g} \ \odot \
						f'(\mathbf{a}^{(k)})$
						\State $\nabla_{\mathbf{b}^{(k)}}J = \mathbf{g} \ + \ \lambda \nabla_{\mathbf{b}^{(k)}}
						\Omega(\theta)$
						\State $\nabla_{\mathbf{W}^{(k)}}J = \mathbf{g}\mathbf{h}^{(k - 1)T} \ + \ \lambda
						\nabla_{\mathbf{W}^{(k)}} \Omega(\theta)$
						\State $\mathbf{g} = \nabla_{\mathbf{h}^{(k - 1)}}J = \mathbf{W}^{(k)T}\mathbf{g}$
					\EndFor
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
	% section the_back-propagation_algorithm (end)

	\section{Loss function is differentiable?} % (fold)
	\label{sec:loss_function_is_differentiable_}

	% section loss_function_is_differentiable_ (end)

% chapter the_network (end)
