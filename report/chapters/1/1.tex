\chapter{The Artificial Neural Network} % (fold)
\label{cha:the_artificial_neural_network}
	In this first chapter, we provide some informations about the Artificial Neural Network, i.e. a fully
	connected Multilayer Perceptron, we implemented from scratch. We'll describe both the network's structure and
	the algorithm we used in order to make our network \textit{learn} from the data used during the testing and
	validation phases. Finally we'll present the loss function we have chosen for our network, and we'll provide
	and explanation on how it is differentiable. We'll use the notation proposed in \cite{Goodfellow-et-al-2016}.

	\section{The ANN's structure} % (fold)
	\label{sec:the_ann_s_structure}
		Since we have to write from scratch an \textit{Artificial Neural Network}, ANN for short, we have
		considered some alternatives before choosing the network's final structure. We agreed on a structure
		composed by:

		\begin{itemize}
			\item one \textit{input layer};
			\item two \textit{hidden layers};
			\item one \textit{output layer};
		\end{itemize}

		As convention, the number of units in the input layer is egual to the number
		of features of the dataset that is used for the learning, validation and testing phases. The two
		hidden layers contain, respectively, four and eight \textit{hidden neurons}, following the convention of
		putting an increasing series of powers of two as number of hidden units per layer. The number of neurons
		for the output layer depends on the kind of task the network is trying to fullfil. In the case of a
		\textit{classification task}, like the MONKS dataset \cite{Dua:2019}, we have decided to put one unit in
		the output layer, while in the case of a \textit{regression task}, like the CUP dataset, we have decided to
		put two units in the output layer. As we have seen studying the papers and books for gathering the
		necessary knowledge for the project, as \cite{Goodfellow-et-al-2016,haykin2009neural,mitchell1997machine},
		choosing to consider the network's structure as an \textit{hyperparameter}, that is, a variable, could
		lead to a series of difficult choices during the validation phase, so we have decided to fix the ANN
		structure to the one described for both the task we have to fullfil, changing only the number of units in
		the output layer from task to task.
	% section the_ann_s_structure (end)

	\section{Initializing the Network} % (fold)
	\label{sec:initializing_the_network}
		As we know from \cite{Goodfellow-et-al-2016,haykin2009neural,mitchell1997machine}, an ANN is composed by
		a set of weights $\mathbf{W}_{i}$, and a set of biases $\mathbf{b}_{i}$,
		$i \in \{ 1, \ \ldots \ , \ l \}$, with $l$ representing the ANN's number of layers. Although it is common
		practice to initialized the network's weights and biases to random, small, values, we have decided to
		follow the \textit{normalized initialization}, as described in
		\cite{Glorot10understandingthe,Goodfellow-et-al-2016}, which defines the initial values for the weights
		and the biases for each layer in the uniform distribution taken in the range

		\begin{equation*}
		    W \sim U \left [ -\frac{\sqrt{6}}{\sqrt{m + n}}, \ \frac{\sqrt{6}}{\sqrt{m + n}} \right ]
		\end{equation*}

		with $m$ and $n$, representing the number of inputs and outputs for each layer. This heuristic is
		designed to compromise between the goal of initializing all layers to have the same activation variance
		and the goal of initializing all layers to have the same gradient variance. The formula is derived using
		the assumption that the network consists only of a chain of matrix multiplications, with no
		nonlinearities. Other than this kind of initialization, we also make available the standard
		\textit{random initialization} for creating a network, described at the beginning of this section, which
		initialize the weights and the biases for each layer in the uniform distribution taken in the range

		\begin{equation*}
		    W \sim U \left [ - 0.7, \ 0.7 \right ].
		\end{equation*}
	% section initializing_the_network (end)

	\section{The back-propagation algorithm} % (fold)
	\label{sec:the_back-propagation_algorithm}
		The learning procedure for our ANN essentialy consist in two distinct phases:

		\begin{enumerate}
			\item compute the network's \textit{gradient}, that is, the derivative of the cost function
			$\nabla_{\theta} J(\theta)$, with $\theta$ representing the ANN's hyperparameters, with respect to
			every network's unit using the well known \textit{back-propagation algorithm};
			\item optimize the information gathered during the first phase using a distinct optimizer, chosen
			among the \textit{Stochastic Gradient Descent} and the \textit{Conjugate Gradient Descent}, as
			described in chapter \ref{cha:optimizers};
		\end{enumerate}

		For computing the gradient we have chosen to use
		the well known \textit{backpropagation algorithm}, firstly introduced in \cite{10028086174} and described
		in \cite{Goodfellow-et-al-2016,haykin2009neural,mitchell1997machine}. This algorithm is
		also composed by two phases, a first phase, that is, the \textit{forward propagation}, in which the
		feature vector $\mathbf{x}$ given in input has to flow from the input layer through the hidden layers and,
		finally, the output layer, giving the approximation $\hat{\mathbf{y}}$ as output, and a second one, that
		is, the \textit{back-propagation}, which allows the informtion to flow backward through the network in
		order to compute the gradient by applying the Chain Rule of Calculus, that is, a formula for computing the
		derivative of a composition of functions.

		\begin{algorithm}[H]
			\caption{Forward propagation through a typical (deep) neural network and the computation of the cost
			function. Here $L(\hat{\mathbf{y}}, \mathbf{y})$ represents the loss function evaluated using both
			$\mathbf{y}$ and $\hat{\mathbf{y}}$ as inputs, more details about that will be provided in
			section \ref{sec:loss_function_is_differentiable_}. The function $f$ applied on line $5$ represents
			the layer's \textit{activation function}, while $\lambda \Omega(\theta)$ represents the
			network's regularization term, with $\theta$ representing the ANN's hyperparameters.}
			\label{alg:forward_propagation}
			\begin{algorithmic}[1]
				\Procedure{Forward propagation}{$l$, $\mathbf{W}_{i} \ i \in \{ 1, \ldots, l \}$,
				$\mathbf{b}_{i} \ i \in \{ 1, \ldots, l \}$, $\mathbf{x}$, $\mathbf{y}$}
					\State $\mathbf{h}_{0} = \mathbf{x}$
					\For{$k = 1, \ldots, l$}
						\State $\mathbf{a}_{k} = \mathbf{b}_{k} + \mathbf{W}_{k}\mathbf{h}_{k - 1}$
						\State $\mathbf{h}_{k} = f(\mathbf{a}_{k})$
					\EndFor
					\State $\hat{\mathbf{y}} = \mathbf{h}_{l}$
					\State $J = L(\hat{\mathbf{y}}, \mathbf{y}) + \lambda \Omega(\theta)$
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}

		Since each one of the ANN's layers has its own
		\textit{activation function}, that is, a function that has to be applyied to the output of every layer's
		neuron, it is particularly usefull to think of the ANN like a composition of functions, and, for this
		reason, the Chain Rule of Calculus play a decisive role in the gradient's computation by back-propagation.
		It is import to note that with the term back-propagation we mean
		only the method for computing the gradient, not the whole learning algorithm. We now provide the
		pseudocode for the forward propagation and the back-propagation phases, as shown in algorithms
		\ref{alg:forward_propagation} and \ref{alg:backward_propagation}.

		\begin{algorithm}[H]
			\caption{Backward computation for the (deep) neural network of algorithm
			\ref{alg:forward_propagation}. Here, the $\odot$ symbol represents the element-wise
			(Hadamard) product, while $\nabla_{\hat{\mathbf{y}}}J =
			\nabla_{\hat{\mathbf{y}}}L(\hat{\mathbf{y}}, \mathbf{y})$ represents the gradient of the loss
			function computed with respect to the output $\hat{\mathbf{y}}$. $\nabla_{\mathbf{b}_{k}}J$,
			$\nabla_{\mathbf{W}_{k}}J$ and $\nabla_{\mathbf{h}_{k - 1}}J$ represents the gradient of the
			loss function computed with respect to, respectively, $\mathbf{b}_{k}$, $\mathbf{W}_{k}$ and
			$\mathbf{h}_{k - 1}$, and finally $\nabla_{\mathbf{b}_{k}} \Omega(\theta)$ and
			$\nabla_{\mathbf{W}_{k}} \Omega(\theta)$ represents the gradient of the ANN's hyperparameters computed
			with respect to, respectively, $\mathbf{b}_{k}$ and $\mathbf{W}_{k}$.}
			\label{alg:backward_propagation}
			\begin{algorithmic}[1]
				\Procedure{Backward propagation}{}
					\State $\mathbf{g} \leftarrow \nabla_{\hat{\mathbf{y}}}J = \nabla_{\hat{\mathbf{y}}}
					L(\hat{\mathbf{y}}, \mathbf{y})$
					\For{$k = l, l - 1, \ldots, 1$}
						\State $\mathbf{g} \leftarrow \nabla_{\mathbf{a}_{k}}J = \mathbf{g} \ \odot \
						f'(\mathbf{a}_{k})$
						\State $\nabla_{\mathbf{b}_{k}}J = \mathbf{g} \ + \ \lambda \nabla_{\mathbf{b}_{k}}
						\Omega(\theta)$
						\State $\nabla_{\mathbf{W}_{k}}J = \mathbf{g}\mathbf{h}_{k - 1}^{T} \ + \ \lambda
						\nabla_{\mathbf{W}_{k}} \Omega(\theta)$
						\State $\mathbf{g} = \nabla_{\mathbf{h}_{k - 1}}J = \mathbf{W}_{k}^{T}\mathbf{g}$
					\EndFor
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
	% section the_back-propagation_algorithm (end)

	\section{The Loss function} % (fold)
	\label{sec:the_loss_function}
		It section \ref{sec:the_back-propagation_algorithm} we have referred to the \textit{Loss function} as to a
		function that takes as input the ANN's output vector $\hat{\mathbf{y}}$ and the \textit{ground truth}
		vector $\mathbf{y}$, that is, the vector containing the desired output for the network. But what
		essentially is a Loss function? As a matter of fact, the Loss function can be considered like
		one way of measuring the performance of the model that utilizes it, an ANN in this case. There are various
		types of Loss functions, for our network we have decided to use two kinds of functions, varying on the
		type of task the ANN is fulfilling, the \textit{Mean Squared Error}, MSE for short, when the task is a
		classification task, and the \textit{Mean Euclidean Error}, MEE for short, when the task is a regression
		task.
	% section the_loss_function (end)

% chapter the_artificial_neural_network (end)
